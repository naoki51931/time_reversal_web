import os
import torch
import numpy as np
from PIL import Image
from diffusers import StableDiffusionImg2ImgPipeline


def generate_motion_frame(
    img_a: Image.Image,
    img_b: Image.Image,
    out_dir="outputs",
    frames=5,
    strength=0.35,
    guidance_scale=18.5,
    prompt=None,
):
    """
    2æšã®ç”»åƒï¼ˆAâ†’Bï¼‰ã®é–“ã‚’è£œé–“ã—ã€
    Stable Diffusion ã«ã‚ˆã£ã¦ã€Œå‰µé€ çš„ã‹ã¤è‡ªç„¶ãªå‹•ä½œä¸­é–“ãƒ•ãƒ¬ãƒ¼ãƒ ã€ã‚’ç”Ÿæˆã€‚

    ç‰¹å¾´:
      - å‰µé€ æ€§ã‚’æˆ»ã—ã€é™çš„ãªç·šå½¢è£œé–“ã«ãƒ©ãƒ³ãƒ€ãƒ å¤‰åŒ–ã‚’è¿½åŠ 
      - å·®åˆ†å¼·åº¦ã«å¿œã˜ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è‡ªå‹•ç”Ÿæˆ
      - fp32å›ºå®šï¼ˆdtypeã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
      - framesæ•°ã«å¿œã˜ã¦æ™‚ç³»åˆ—çš„ãªæ»‘ã‚‰ã‹ã•ã‚’ç¶­æŒ
    """

    os.makedirs(out_dir, exist_ok=True)
    device = "cuda" if torch.cuda.is_available() else "cpu"

    try:
        # === 1ï¸âƒ£ Stable Diffusion Pipeline ===
        pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
            "runwayml/stable-diffusion-v1-5",
            torch_dtype=torch.float32,  # âœ… fp32ã§å®‰å…¨å®Ÿè¡Œ
        ).to(device)

        # safety_checkerç„¡åŠ¹åŒ–
        def dummy_checker(images, **kwargs):
            return images, [False] * len(images)
        pipe.safety_checker = dummy_checker

        # === 2ï¸âƒ£ å·®åˆ†è§£æ ===
        arr_a = np.array(img_a).astype(np.float32)
        arr_b = np.array(img_b).astype(np.float32)
        diff_intensity = float(np.mean(np.abs(arr_b - arr_a)))
        print(f"[Motion] Difference Intensity: {diff_intensity:.2f}")

        # === 3ï¸âƒ£ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ ===
        if prompt:
            base_prompt = prompt
        elif diff_intensity < 5:
            base_prompt = "subtle facial motion, blinking, breathing, natural small movement, same subject"
        elif diff_intensity < 20:
            base_prompt = "smooth head or body motion, natural pose transition, same character, cinematic lighting"
        else:
            base_prompt = "dynamic body motion, action transition, realistic cinematic frame, same person continuity"

        print(f"[Motion] Motion Prompt: {base_prompt}")

        # === 4ï¸âƒ£ ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆ ===
        frame_paths = []
        arr_a = np.array(img_a).astype(np.float32)
        arr_b = np.array(img_b).astype(np.float32)

        for i in range(1, frames + 1):
            t = i / (frames + 1)

            # ğŸ” ç·šå½¢è£œé–“ + å‰µé€ çš„ãƒã‚¤ã‚ºï¼ˆã‚·ãƒ¼ãƒ³ã®æƒ³åƒåŠ›ã‚’åˆºæ¿€ï¼‰
            blend = arr_a * (1 - t) + arr_b * t
            # ãƒã‚¤ã‚ºã®å¼·åº¦ã‚’æ™‚é–“ä½ç½®ã«å¿œã˜ã¦å¯å¤‰ï¼ˆä¸­é–“ã§æœ€å¤§ï¼‰
            noise_intensity = (np.sin(np.pi * t) ** 2) * 20
            noise = np.random.normal(0, noise_intensity, blend.shape)
            blended = np.clip(blend + noise, 0, 255).astype(np.uint8)
            mid_img = Image.fromarray(blended)

            # ğŸ¨ å‰µé€ çš„ãªæ‹¡å¼µãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            creative_prompt = (
                f"{base_prompt}, frame {i}/{frames}, lineart, smooth interpolation, cinematic atmosphere, "
                "fluid motion between poses, dynamic energy, consistent character identity"
            )

            print(f"[Motion] Frame {i}/{frames} â†’ noise={noise_intensity:.1f}, strength={strength:.2f}")

            # === 5ï¸âƒ£ Diffusionå†ç”Ÿæˆ ===
            result = pipe(
                prompt=creative_prompt,
                image=mid_img,
                strength=strength,
                guidance_scale=guidance_scale,
                num_inference_steps=40,
            )

            if not hasattr(result, "images") or not result.images:
                print(f"[WARN] Frame {i}: invalid result, skipping.")
                continue

            img_out = result.images[0]
            if isinstance(img_out, bool):
                img_out = mid_img

            out_path = os.path.join(out_dir, f"motion_frame_{i:02d}.png")
            img_out.save(out_path)
            frame_paths.append(out_path)

        print(f"[Motion] Generated {len(frame_paths)} creative frames.")
        return frame_paths

    except Exception as e:
        print(f"[Motion] Diffusion pipeline error: {e}")
        return []

